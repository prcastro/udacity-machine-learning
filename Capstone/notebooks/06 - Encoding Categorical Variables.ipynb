{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-16 00:42:45.813242. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-16 00:42:46.469495. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def gini(actual, pred):\n",
    "    assert (len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "    totalLosses = all[:, 0].sum()\n",
    "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
    "\n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "\n",
    "def gini_normalized(actual, pred):\n",
    "    return gini(actual, pred) / gini(actual, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-16 00:42:46.493811. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")\n",
    "X, y = data.loc[:, data.columns != \"target\"], data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.271380686266\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "mean_gini = gini_normalized(y_test, y_pred)\n",
    "print(mean_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = data.loc[:, data.columns != \"target\"], data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns[X.columns.str.endswith(\"cat\")]:\n",
    "    X.loc[:, col] = X.loc[:, col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.271336978717\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "mean_gini = gini_normalized(y_test, y_pred)\n",
    "print(mean_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.273417686925\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train.fillna(X_train.median()), y_train)\n",
    "y_pred = model.predict_proba(X_test.fillna(X_test.median()))[:, 1]\n",
    "\n",
    "mean_gini = gini_normalized(y_test, y_pred)\n",
    "print(mean_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 ms, sys: 13.3 ms, total: 228 ms\n",
      "Wall time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resampler = RandomUnderSampler()\n",
    "indexes = X_train.index.values.reshape(-1, 1)\n",
    "index_res, y_res = resampler.fit_sample(indexes, y_train)\n",
    "X_res = X_train.loc[index_res.flatten(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.268508048273\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_res, y_res)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "mean_gini = gini_normalized(y_test, y_pred)\n",
    "print(mean_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Target Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k, f):\n",
    "        self.k = k\n",
    "        self.f = f\n",
    "        \n",
    "    \n",
    "    def _smoothing(self, n, k, f):\n",
    "        return 1 / (1+np.exp(-(n-k)/f))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.prior = y.mean()\n",
    "        self.encoding_dicts = {}\n",
    "        for col in X.columns:\n",
    "            mean_col = y.groupby(X[col]).mean()\n",
    "            counts = X[col].value_counts()\n",
    "            s = counts.apply(lambda n: self._smoothing(n, self.k, self.f))\n",
    "            encoding = s * mean_col + (1-s) * self.prior\n",
    "            self.encoding_dicts[col] = encoding.to_dict()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_enc = X.copy()\n",
    "        for col in X.columns:\n",
    "            X_enc[col] = X[col].apply(lambda n: self.encoding_dicts[col].get(n, self.prior))\n",
    "        return X_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")\n",
    "X, y = data.loc[:, data.columns != \"target\"], data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "target_encoder = TargetEncoder(1, 1)\n",
    "cat_cols = X_train.columns[X_train.columns.str.endswith(\"cat\")]\n",
    "X_train.loc[:, cat_cols] = target_encoder.fit_transform(X_train.loc[:, cat_cols], y)\n",
    "X_test.loc[:, cat_cols] = target_encoder.transform(X_test.loc[:, cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.272827229709\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "mean_gini = gini_normalized(y_test, y_pred)\n",
    "print(mean_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.273845739752\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train.fillna(X_train.median()), y_train)\n",
    "y_pred = model.predict_proba(X_test.fillna(X_test.median()))[:, 1]\n",
    "\n",
    "mean_gini = gini_normalized(y_test, y_pred)\n",
    "print(mean_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 6.68 ms, total: 183 ms\n",
      "Wall time: 181 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resampler = RandomUnderSampler()\n",
    "indexes = X_train.index.values.reshape(-1, 1)\n",
    "index_res, y_res = resampler.fit_sample(indexes, y_train)\n",
    "X_res = X_train.loc[index_res.flatten(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.269984222218\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_res, y_res)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "mean_gini = gini_normalized(y_test, y_pred)\n",
    "print(mean_gini)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
