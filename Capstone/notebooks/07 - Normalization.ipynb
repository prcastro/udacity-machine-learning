{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-13 14:38:51.070087. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-13 14:38:51.636158. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "def gini(actual, pred):\n",
    "    assert (len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "    totalLosses = all[:, 0].sum()\n",
    "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
    "\n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "\n",
    "def gini_normalized(actual, pred):\n",
    "    return gini(actual, pred) / gini(actual, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-13 14:38:51.858504. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")\n",
    "X, y = data.loc[:, data.columns != \"target\"], data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "resampler = RandomUnderSampler()\n",
    "indexes = X_train.index.values.reshape(-1, 1)\n",
    "index_res, y_res = resampler.fit_sample(indexes, y_train)\n",
    "X_res = X_train.loc[index_res.flatten(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-13 14:38:56.377577. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")\n",
    "X, y = data.loc[:, data.columns != \"target\"], data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "resampler = RandomUnderSampler()\n",
    "indexes = X_train.index.values.reshape(-1, 1)\n",
    "index_res, y_res = resampler.fit_sample(indexes, y_train)\n",
    "X_res = X_train.loc[index_res.flatten(), :]\n",
    "X_mean = X_res.fillna(X_res.mean())\n",
    "X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/json/encoder.py:199: DeprecationWarning: Interpreting naive datetime as local 2017-11-13 14:39:00.859791. Please add timezone info to timestamps.\n",
      "  chunks = self.iterencode(o, _one_shot=True)\n"
     ]
    }
   ],
   "source": [
    "float_cols = X_mean.columns[(~X_mean.columns.str.contains(\"bin|cat\")) & (X_mean.dtypes == \"float64\")]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_mean[float_cols])\n",
    "X_mean[float_cols] = scaler.transform(X_mean[float_cols])\n",
    "X_test[float_cols] = scaler.transform(X_test[float_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.266443006543\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_mean, y_res)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "std_gini = gini_normalized(y_test, y_pred)\n",
    "print(std_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")\n",
    "X, y = data.loc[:, data.columns != \"target\"], data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "resampler = RandomUnderSampler()\n",
    "indexes = X_train.index.values.reshape(-1, 1)\n",
    "index_res, y_res = resampler.fit_sample(indexes, y_train)\n",
    "X_res = X_train.loc[index_res.flatten(), :]\n",
    "X_mean = X_res.fillna(X_res.mean())\n",
    "X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_cols = X_mean.columns[(~X_mean.columns.str.contains(\"bin|cat\")) & (X_mean.dtypes == \"float64\")]\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_mean[float_cols])\n",
    "X_mean[float_cols] = scaler.transform(X_mean[float_cols])\n",
    "X_test[float_cols] = scaler.transform(X_test[float_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.267536751355\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_mean, y_res)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "robust_gini = gini_normalized(y_test, y_pred)\n",
    "print(robust_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAbsScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")\n",
    "X, y = data.loc[:, data.columns != \"target\"], data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "resampler = RandomUnderSampler()\n",
    "indexes = X_train.index.values.reshape(-1, 1)\n",
    "index_res, y_res = resampler.fit_sample(indexes, y_train)\n",
    "X_res = X_train.loc[index_res.flatten(), :]\n",
    "X_mean = X_res.fillna(X_res.mean())\n",
    "X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_cols = X_mean.columns[(~X_mean.columns.str.contains(\"bin|cat\")) & (X_mean.dtypes == \"float64\")]\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X_mean[float_cols])\n",
    "X_mean[float_cols] = scaler.transform(X_mean[float_cols])\n",
    "X_test[float_cols] = scaler.transform(X_test[float_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.262684254465\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_mean, y_res)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "maxabs_gini = gini_normalized(y_test, y_pred)\n",
    "print(maxabs_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train.csv\", na_values=[-1, -1.0], index_col=\"id\")\n",
    "X, y = data.loc[:, data.columns != \"target\"], data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "resampler = RandomUnderSampler()\n",
    "indexes = X_train.index.values.reshape(-1, 1)\n",
    "index_res, y_res = resampler.fit_sample(indexes, y_train)\n",
    "X_res = X_train.loc[index_res.flatten(), :]\n",
    "X_mean = X_res.fillna(X_res.mean())\n",
    "X_test = X_test.fillna(X_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "float_cols = X_mean.columns[(~X_mean.columns.str.contains(\"bin|cat\")) & (X_mean.dtypes == \"float64\")]\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_mean[float_cols])\n",
    "X_mean[float_cols] = scaler.transform(X_mean[float_cols])\n",
    "X_test[float_cols] = scaler.transform(X_test[float_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_mean, y_res)\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "minmax_gini = gini_normalized(y_test, y_pred)\n",
    "print(minmax_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.bar([\"Std Scaling\", \"Robust Scaling\", \"Max Abs\", \"Min Max\"], [std_gini, robust_gini, maxabs_gini, minmax_gini])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
